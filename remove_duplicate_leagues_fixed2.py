#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üßπ Remove Duplicate Leagues from Index HTML (Fixed 2)
‡∏•‡∏ö‡∏•‡∏µ‡∏Å‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ index.html (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2)
"""

import os
from bs4 import BeautifulSoup

def load_index_html():
    """Load current index.html"""
    try:
        with open('index.html', 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f, 'html.parser')
            return soup
    except:
        print("Error: Could not load index.html")
        return None

def remove_duplicate_leagues(soup):
    """Remove duplicate leagues"""
    if not soup:
        return None
    
    # Define league mappings (equivalent leagues)
    league_mappings = {
        "Norway - Tippeligaen": "Norway - Eliteserien",
        "Iceland - Premier League": "Iceland - √örvalsdeild",
        "Denmark - Division 1": "Denmark - 1. Division",
        "Finland - Ykkonen": "Finland - Ykk√∂nen"
    }
    
    # Find all league sections (cards)
    league_cards = soup.select('div.card.mb-4')
    
    # Keep track of leagues we've seen
    seen_leagues = {}
    cards_to_remove = []
    
    # First pass: identify duplicates
    for i, card in enumerate(league_cards):
        header = card.select_one('div.card-header h2')
        if header:
            header_text = header.text.strip()
            
            # Extract league name (remove date)
            league_name = header_text.split(" - July")[0] if " - July" in header_text else header_text
            
            # Check if this league has an equivalent name
            normalized_league_name = league_mappings.get(league_name, league_name)
            
            # Check if we've seen this league before
            if normalized_league_name in seen_leagues:
                # Mark for removal
                cards_to_remove.append(i)
                print(f"Marking for removal: {league_name}")
            else:
                # Mark this league as seen
                seen_leagues[normalized_league_name] = True
                print(f"Keeping: {league_name}")
    
    # Second pass: remove duplicates (in reverse order to avoid index issues)
    for i in sorted(cards_to_remove, reverse=True):
        if i < len(league_cards):
            league_cards[i].extract()
            print(f"Removed card at index {i}")
    
    return soup

def save_updated_index(soup, filename="index.html"):
    """Save updated index.html"""
    if not soup:
        return False
    
    # Create a backup of the original file
    try:
        with open('index.html', 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        with open('index.html.bak_duplicates2', 'w', encoding='utf-8') as f:
            f.write(original_content)
    except:
        print("Warning: Could not create backup of index.html")
    
    # Save the updated file
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(str(soup))
        
        print(f"Updated index.html saved successfully")
        return True
    except Exception as e:
        print(f"Error saving updated index.html: {str(e)}")
        return False

def main():
    # Load current index.html
    index_soup = load_index_html()
    
    if not index_soup:
        print("Could not load index.html. Please make sure it exists.")
        return
    
    # Remove duplicate leagues
    updated_soup = remove_duplicate_leagues(index_soup)
    
    if not updated_soup:
        print("Failed to remove duplicate leagues from index.html.")
        return
    
    # Save updated index.html
    success = save_updated_index(updated_soup)
    
    if success:
        print("Successfully removed duplicate leagues from index.html.")
    else:
        print("Failed to save updated index.html.")

if __name__ == "__main__":
    main()
