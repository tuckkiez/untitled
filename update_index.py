#!/usr/bin/env python3
"""
üöÄ Update Index HTML - July 18, 2025
‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏´‡∏ô‡πâ‡∏≤ index.html ‡∏î‡πâ‡∏ß‡∏¢‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
"""

import os
import re
import json
from datetime import datetime
from bs4 import BeautifulSoup

class IndexUpdater:
    """Index HTML Updater"""
    
    def __init__(self):
        """Initialize the updater"""
        self.project_dir = "/Users/80090/Desktop/Project/untitle"
        self.index_file = os.path.join(self.project_dir, "index.html")
        self.output_dir = os.path.join(self.project_dir, "output")
        
        print("üöÄ Initializing Index HTML Updater")
    
    def load_index_html(self):
        """Load the index.html file"""
        print(f"üìÑ Loading index.html from {self.index_file}...")
        
        try:
            with open(self.index_file, "r", encoding="utf-8") as f:
                html_content = f.read()
            
            print("‚úÖ Successfully loaded index.html")
            return html_content
        except Exception as e:
            print(f"‚ùå Error loading index.html: {str(e)}")
            
            # Create a basic index.html if it doesn't exist
            html_content = """
            <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>Ultra Advanced Multi-League Football Predictor</title>
                <style>
                    body {
                        font-family: Arial, sans-serif;
                        line-height: 1.6;
                        margin: 0;
                        padding: 20px;
                        color: #333;
                    }
                    h1, h2, h3 {
                        color: #0066cc;
                    }
                    .container {
                        max-width: 1200px;
                        margin: 0 auto;
                    }
                    .league-section {
                        margin-bottom: 30px;
                        padding: 20px;
                        border: 1px solid #ddd;
                        border-radius: 5px;
                    }
                    table {
                        width: 100%;
                        border-collapse: collapse;
                        margin-bottom: 20px;
                    }
                    th, td {
                        padding: 12px 15px;
                        border: 1px solid #ddd;
                        text-align: left;
                    }
                    th {
                        background-color: #0066cc;
                        color: white;
                    }
                    tr:nth-child(even) {
                        background-color: #f2f2f2;
                    }
                    .value-bet {
                        background-color: #dff0d8;
                        font-weight: bold;
                    }
                    .high-probability {
                        color: #0066cc;
                        font-weight: bold;
                    }
                    .footer {
                        margin-top: 30px;
                        text-align: center;
                        font-size: 0.8em;
                        color: #666;
                    }
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>üöÄ Ultra Advanced Multi-League Football Predictor</h1>
                    <p>‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏ü‡∏∏‡∏ï‡∏ö‡∏≠‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏•‡∏µ‡∏Å‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ Machine Learning ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á <strong>‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå</strong></p>
                    
                    <!-- China Super League Section -->
                    <div id="china-super-league" class="league-section">
                        <h2>üá®üá≥ China Super League Analysis</h2>
                        <p>Date: Waiting for update...</p>
                        <p>No data available yet.</p>
                    </div>
                    
                    <!-- Korea K League 1 Section -->
                    <div id="korea-k-league" class="league-section">
                        <h2>üá∞üá∑ Korea K League 1 Analysis</h2>
                        <p>Date: Waiting for update...</p>
                        <p>No data available yet.</p>
                    </div>
                    
                    <div class="footer">
                        <p>Generated by Ultra Advanced ML Football Predictor</p>
                        <p>¬© 2025 All Rights Reserved</p>
                    </div>
                </div>
            </body>
            </html>
            """
            
            print("‚úÖ Created basic index.html template")
            return html_content
    
    def load_china_super_league_results(self):
        """Load China Super League analysis results"""
        print("üìä Loading China Super League analysis results...")
        
        # Find the latest report file
        report_files = [f for f in os.listdir(self.output_dir) if f.startswith("china_super_league_analysis_") and f.endswith(".html")]
        
        if not report_files:
            print("‚ùå No China Super League analysis reports found")
            return None
        
        latest_report = sorted(report_files)[-1]
        report_path = os.path.join(self.output_dir, latest_report)
        
        try:
            with open(report_path, "r", encoding="utf-8") as f:
                report_content = f.read()
            
            print(f"‚úÖ Successfully loaded China Super League report: {latest_report}")
            return report_content
        except Exception as e:
            print(f"‚ùå Error loading China Super League report: {str(e)}")
            return None
    
    def load_korea_k_league_results(self):
        """Load Korea K League 1 analysis results"""
        print("üìä Loading Korea K League 1 analysis results...")
        
        # Find the latest report file - prioritize Ultra analysis
        ultra_report_files = [f for f in os.listdir(self.output_dir) if f.startswith("korea_k_league_ultra_analysis_") and f.endswith(".html")]
        regular_report_files = [f for f in os.listdir(self.output_dir) if f.startswith("korea_k_league_analysis_") and f.endswith(".html")]
        
        if ultra_report_files:
            latest_report = sorted(ultra_report_files)[-1]
        elif regular_report_files:
            latest_report = sorted(regular_report_files)[-1]
        else:
            print("‚ùå No Korea K League 1 analysis reports found")
            return None
        
        report_path = os.path.join(self.output_dir, latest_report)
        
        try:
            with open(report_path, "r", encoding="utf-8") as f:
                report_content = f.read()
            
            print(f"‚úÖ Successfully loaded Korea K League 1 report: {latest_report}")
            return report_content
        except Exception as e:
            print(f"‚ùå Error loading Korea K League 1 report: {str(e)}")
            return None
    
    def extract_league_content(self, report_content):
        """Extract league content from report"""
        if not report_content:
            return None
        
        soup = BeautifulSoup(report_content, "html.parser")
        
        # Extract date
        date_text = soup.find("p", string=lambda text: text and text.startswith("Date:"))
        date = date_text.text if date_text else f"Date: {datetime.now().strftime('%Y-%m-%d')}"
        
        # Extract tables
        tables = soup.find_all("table")
        
        if len(tables) < 2:
            return None
        
        match_predictions_table = tables[0].prettify()
        corner_analysis_table = tables[1].prettify()
        
        return {
            "date": date,
            "match_predictions_table": match_predictions_table,
            "corner_analysis_table": corner_analysis_table
        }
    
    def update_index_html(self, html_content, china_content, korea_content):
        """Update the index.html content"""
        print("üîÑ Updating index.html content...")
        
        soup = BeautifulSoup(html_content, "html.parser")
        
        # Update China Super League section
        if china_content:
            china_section = soup.find("div", id="china-super-league")
            if china_section:
                # Update date
                date_p = china_section.find("p")
                if date_p:
                    date_p.string = china_content["date"]
                else:
                    date_p = soup.new_tag("p")
                    date_p.string = china_content["date"]
                    china_section.append(date_p)
                
                # Remove existing content except h2 and date
                for tag in list(china_section.children)[2:]:
                    if tag.name:
                        tag.decompose()
                
                # Add match predictions
                match_h3 = soup.new_tag("h3")
                match_h3.string = "Match Predictions"
                china_section.append(match_h3)
                
                match_table = BeautifulSoup(china_content["match_predictions_table"], "html.parser")
                china_section.append(match_table)
                
                # Add corner analysis
                corner_h3 = soup.new_tag("h3")
                corner_h3.string = "Corner Analysis (Over/Under 10.0)"
                china_section.append(corner_h3)
                
                corner_table = BeautifulSoup(china_content["corner_analysis_table"], "html.parser")
                china_section.append(corner_table)
        
        # Update Korea K League 1 section
        if korea_content:
            korea_section = soup.find("div", id="korea-k-league")
            if korea_section:
                # Update date
                date_p = korea_section.find("p")
                if date_p:
                    date_p.string = korea_content["date"]
                else:
                    date_p = soup.new_tag("p")
                    date_p.string = korea_content["date"]
                    korea_section.append(date_p)
                
                # Remove existing content except h2 and date
                for tag in list(korea_section.children)[2:]:
                    if tag.name:
                        tag.decompose()
                
                # Add match predictions
                match_h3 = soup.new_tag("h3")
                match_h3.string = "Match Predictions"
                korea_section.append(match_h3)
                
                match_table = BeautifulSoup(korea_content["match_predictions_table"], "html.parser")
                korea_section.append(match_table)
                
                # Add corner analysis
                corner_h3 = soup.new_tag("h3")
                corner_h3.string = "Corner Analysis (Over/Under 10.0)"
                korea_section.append(corner_h3)
                
                corner_table = BeautifulSoup(korea_content["corner_analysis_table"], "html.parser")
                korea_section.append(corner_table)
        
        # Update the last updated time
        footer = soup.find("div", class_="footer")
        if footer:
            last_updated_p = footer.find("p", string=lambda text: text and "Last updated" in text)
            if last_updated_p:
                last_updated_p.string = f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            else:
                last_updated_p = soup.new_tag("p")
                last_updated_p.string = f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                footer.insert(0, last_updated_p)
        
        print("‚úÖ Successfully updated index.html content")
        return str(soup)
    
    def save_index_html(self, html_content):
        """Save the updated index.html file"""
        print(f"üíæ Saving updated index.html to {self.index_file}...")
        
        try:
            with open(self.index_file, "w", encoding="utf-8") as f:
                f.write(html_content)
            
            print("‚úÖ Successfully saved updated index.html")
            return True
        except Exception as e:
            print(f"‚ùå Error saving index.html: {str(e)}")
            return False
    
    def run_update(self):
        """Run the complete update process"""
        print("üöÄ Running complete index.html update...")
        
        # 1. Load index.html
        html_content = self.load_index_html()
        
        # 2. Load league results
        china_report = self.load_china_super_league_results()
        korea_report = self.load_korea_k_league_results()
        
        # 3. Extract league content
        china_content = self.extract_league_content(china_report)
        korea_content = self.extract_league_content(korea_report)
        
        # 4. Update index.html
        updated_html = self.update_index_html(html_content, china_content, korea_content)
        
        # 5. Save updated index.html
        success = self.save_index_html(updated_html)
        
        if success:
            print("‚úÖ Index.html update complete!")
        else:
            print("‚ùå Index.html update failed!")
        
        return success

def main():
    """Main function"""
    updater = IndexUpdater()
    updater.run_update()

if __name__ == "__main__":
    main()
