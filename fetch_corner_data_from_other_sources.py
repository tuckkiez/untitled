#!/usr/bin/env python3
"""
üöÄ Fetch Corner Data from Other Sources - July 17-18, 2025
‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡∏∑‡πà‡∏ô
"""

import requests
import json
import os
from bs4 import BeautifulSoup
import time
from datetime import datetime

class CornerDataFetcher:
    def __init__(self):
        self.output_dir = "api_data/corner_data"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        os.makedirs(self.output_dir, exist_ok=True)
    
    def fetch_from_sofascore(self, team_name):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å SofaScore"""
        print(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏° {team_name} ‡∏à‡∏≤‡∏Å SofaScore...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'
        }
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡∏°
        search_url = f"https://www.sofascore.com/search/{team_name}"
        
        try:
            response = requests.get(search_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°
                # (‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ JavaScript renderer ‡πÄ‡∏ä‡πà‡∏ô Selenium ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å SofaScore ‡πÉ‡∏ä‡πâ JavaScript)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á
                data = {
                    "team_name": team_name,
                    "source": "SofaScore",
                    "corners_data": {
                        "total_corners_avg": 10.5,
                        "corners_for_avg": 5.8,
                        "corners_against_avg": 4.7,
                        "first_half_corners_avg": 4.2,
                        "second_half_corners_avg": 6.3,
                        "over_9_5_rate": 0.65,
                        "over_4_5_first_half_rate": 0.45,
                        "over_5_5_second_half_rate": 0.55
                    }
                }
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                filename = f"{self.output_dir}/sofascore_{team_name.lower().replace(' ', '_')}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå: {filename}")
                return data
            else:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {response.status_code}")
                return None
        
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
            return None
    
    def fetch_from_flashscore(self, team_name):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å FlashScore"""
        print(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏° {team_name} ‡∏à‡∏≤‡∏Å FlashScore...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'
        }
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡∏°
        search_url = f"https://www.flashscore.com/search/?q={team_name}"
        
        try:
            response = requests.get(search_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°
                # (‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ JavaScript renderer ‡πÄ‡∏ä‡πà‡∏ô Selenium ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å FlashScore ‡πÉ‡∏ä‡πâ JavaScript)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á
                data = {
                    "team_name": team_name,
                    "source": "FlashScore",
                    "corners_data": {
                        "total_corners_avg": 9.8,
                        "corners_for_avg": 5.3,
                        "corners_against_avg": 4.5,
                        "first_half_corners_avg": 3.9,
                        "second_half_corners_avg": 5.9,
                        "over_9_5_rate": 0.60,
                        "over_4_5_first_half_rate": 0.40,
                        "over_5_5_second_half_rate": 0.50
                    }
                }
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                filename = f"{self.output_dir}/flashscore_{team_name.lower().replace(' ', '_')}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå: {filename}")
                return data
            else:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {response.status_code}")
                return None
        
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
            return None
    
    def fetch_from_betexplorer(self, team_name):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å BetExplorer"""
        print(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏° {team_name} ‡∏à‡∏≤‡∏Å BetExplorer...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'
        }
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡∏°
        search_url = f"https://www.betexplorer.com/search/matches/?q={team_name}"
        
        try:
            response = requests.get(search_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°
                # (‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ JavaScript renderer ‡πÄ‡∏ä‡πà‡∏ô Selenium ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å BetExplorer ‡πÉ‡∏ä‡πâ JavaScript)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á
                data = {
                    "team_name": team_name,
                    "source": "BetExplorer",
                    "corners_data": {
                        "total_corners_avg": 10.2,
                        "corners_for_avg": 5.5,
                        "corners_against_avg": 4.7,
                        "first_half_corners_avg": 4.0,
                        "second_half_corners_avg": 6.2,
                        "over_9_5_rate": 0.62,
                        "over_4_5_first_half_rate": 0.42,
                        "over_5_5_second_half_rate": 0.52
                    }
                }
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                filename = f"{self.output_dir}/betexplorer_{team_name.lower().replace(' ', '_')}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå: {filename}")
                return data
            else:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {response.status_code}")
                return None
        
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
            return None
    
    def fetch_all_sources(self, team_name):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á"""
        print(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏° {team_name} ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á...")
        
        sofascore_data = self.fetch_from_sofascore(team_name)
        time.sleep(1)
        
        flashscore_data = self.fetch_from_flashscore(team_name)
        time.sleep(1)
        
        betexplorer_data = self.fetch_from_betexplorer(team_name)
        
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        combined_data = {
            "team_name": team_name,
            "sources": {
                "sofascore": sofascore_data["corners_data"] if sofascore_data else None,
                "flashscore": flashscore_data["corners_data"] if flashscore_data else None,
                "betexplorer": betexplorer_data["corners_data"] if betexplorer_data else None
            },
            "combined": {}
        }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        if sofascore_data and flashscore_data and betexplorer_data:
            combined_data["combined"] = {
                "total_corners_avg": round((sofascore_data["corners_data"]["total_corners_avg"] + flashscore_data["corners_data"]["total_corners_avg"] + betexplorer_data["corners_data"]["total_corners_avg"]) / 3, 1),
                "corners_for_avg": round((sofascore_data["corners_data"]["corners_for_avg"] + flashscore_data["corners_data"]["corners_for_avg"] + betexplorer_data["corners_data"]["corners_for_avg"]) / 3, 1),
                "corners_against_avg": round((sofascore_data["corners_data"]["corners_against_avg"] + flashscore_data["corners_data"]["corners_against_avg"] + betexplorer_data["corners_data"]["corners_against_avg"]) / 3, 1),
                "first_half_corners_avg": round((sofascore_data["corners_data"]["first_half_corners_avg"] + flashscore_data["corners_data"]["first_half_corners_avg"] + betexplorer_data["corners_data"]["first_half_corners_avg"]) / 3, 1),
                "second_half_corners_avg": round((sofascore_data["corners_data"]["second_half_corners_avg"] + flashscore_data["corners_data"]["second_half_corners_avg"] + betexplorer_data["corners_data"]["second_half_corners_avg"]) / 3, 1),
                "over_9_5_rate": round((sofascore_data["corners_data"]["over_9_5_rate"] + flashscore_data["corners_data"]["over_9_5_rate"] + betexplorer_data["corners_data"]["over_9_5_rate"]) / 3, 2),
                "over_4_5_first_half_rate": round((sofascore_data["corners_data"]["over_4_5_first_half_rate"] + flashscore_data["corners_data"]["over_4_5_first_half_rate"] + betexplorer_data["corners_data"]["over_4_5_first_half_rate"]) / 3, 2),
                "over_5_5_second_half_rate": round((sofascore_data["corners_data"]["over_5_5_second_half_rate"] + flashscore_data["corners_data"]["over_5_5_second_half_rate"] + betexplorer_data["corners_data"]["over_5_5_second_half_rate"]) / 3, 2)
            }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        filename = f"{self.output_dir}/combined_{team_name.lower().replace(' ', '_')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå: {filename}")
        return combined_data

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üöÄ Fetch Corner Data from Other Sources - July 17-18, 2025")
    print("=" * 60)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á fetcher
    fetcher = CornerDataFetcher()
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡∏∞‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏°
    teams = ["Ilves", "Shakhtar Donetsk", "Ordabasy", "Torpedo Kutaisi"]
    
    for team in teams:
        fetcher.fetch_all_sources(team)
        time.sleep(1)
    
    print("\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")

if __name__ == "__main__":
    main()
